{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained model tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'after', 'stealing', 'money', 'from', 'the', 'bank', 'vault', ',', 'the', 'bank', 'robber', 'was', 'seen', 'fishing', 'on', 'the', 'mississippi', 'river', 'bank', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "# Tokenize our sentence with the BERT tokenizer.\n",
    "tokenized_text = tokenizer.tokenize(marked_text)\n",
    "\n",
    "# Print out the tokens.\n",
    "print (tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]           101\n",
      "after         2,044\n",
      "stealing     11,065\n",
      "money         2,769\n",
      "from          2,013\n",
      "the           1,996\n",
      "bank          2,924\n",
      "vault        11,632\n",
      ",             1,010\n",
      "the           1,996\n",
      "bank          2,924\n",
      "robber       27,307\n",
      "was           2,001\n",
      "seen          2,464\n",
      "fishing       5,645\n",
      "on            2,006\n",
      "the           1,996\n",
      "mississippi   5,900\n",
      "river         2,314\n",
      "bank          2,924\n",
      ".             1,012\n",
      "[SEP]           102\n"
     ]
    }
   ],
   "source": [
    "# Map the token strings to their vocabulary indeces.\n",
    "indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "\n",
    "# Display the words with their indeces.\n",
    "for tup in zip(tokenized_text, indexed_tokens):\n",
    "    print('{:<12} {:>6,}'.format(tup[0], tup[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# Mark each of the 22 tokens as belonging to sentence \"1\".\n",
    "segments_ids = [1] * len(tokenized_text)\n",
    "print (segments_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): BertLayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): BertLayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): BertLayerNorm()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert inputs to PyTorch tensors\n",
    "tokens_tensor = torch.tensor([indexed_tokens])\n",
    "segments_tensors = torch.tensor([segments_ids])\n",
    "\n",
    "# Load pre-trained model (weights)\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    encoded_layers, _ = model(tokens_tensor, segments_tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.2645,  0.0118, -0.5196,  ..., -0.0293,  0.3886,  0.5092],\n",
       "         [-0.2265, -0.2834, -0.0875,  ..., -0.5227, -0.0107, -0.2487],\n",
       "         [-0.4162, -0.4183,  0.0928,  ..., -0.3227, -0.2965, -0.2034],\n",
       "         ...,\n",
       "         [ 0.2947, -0.2835, -0.0351,  ..., -0.5340, -0.2271,  0.1018],\n",
       "         [ 0.6511, -0.0945, -0.1933,  ...,  0.0790, -0.4076, -0.2446],\n",
       "         [-0.1565, -0.0090, -0.1407,  ...,  0.4275,  0.2381, -0.4106]]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_layers[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers: 12\n",
      "Number of batches: 1\n",
      "Number of tokens: 22\n",
      "Number of hidden units: 768\n"
     ]
    }
   ],
   "source": [
    "print (\"Number of layers:\", len(encoded_layers))\n",
    "layer_i = 0\n",
    "print (\"Number of batches:\", len(encoded_layers[layer_i]))\n",
    "batch_i = 0\n",
    "print (\"Number of tokens:\", len(encoded_layers[layer_i][batch_i]))\n",
    "token_i = 0\n",
    "print (\"Number of hidden units:\", len(encoded_layers[layer_i][batch_i][token_i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([22, 12, 768])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "token_embeddings = token_embeddings.permute(1,0,2)\n",
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape is: 22 x 768\n"
     ]
    }
   ],
   "source": [
    "# Stores the token vectors, with shape [22 x 768]\n",
    "token_vecs_sum = []\n",
    "\n",
    "# For each token in the sentence...\n",
    "for token in token_embeddings:\n",
    "    # `token` is a [12 x 768] tensor\n",
    "    # Sum the vectors from the last four layers.\n",
    "    sum_vec = torch.sum(token[-4:], dim=0)\n",
    "    # Use `sum_vec` to represent `token`.\n",
    "    token_vecs_sum.append(sum_vec)\n",
    "\n",
    "print ('Shape is: %d x %d' % (len(token_vecs_sum), len(token_vecs_sum[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [CLS]\n",
      "1 after\n",
      "2 stealing\n",
      "3 money\n",
      "4 from\n",
      "5 the\n",
      "6 bank\n",
      "7 vault\n",
      "8 ,\n",
      "9 the\n",
      "10 bank\n",
      "11 robber\n",
      "12 was\n",
      "13 seen\n",
      "14 fishing\n",
      "15 on\n",
      "16 the\n",
      "17 mississippi\n",
      "18 river\n",
      "19 bank\n",
      "20 .\n",
      "21 [SEP]\n"
     ]
    }
   ],
   "source": [
    "for i, token_str in enumerate(tokenized_text):\n",
    "    print(i, token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 vector values for each instance of \"bank\".\n",
      "\n",
      "bank vault    tensor([ 2.1319, -2.1413, -1.6260,  0.8638,  3.3173])\n",
      "bank robber   tensor([ 1.1868, -1.5298, -1.3770,  1.0648,  3.1446])\n",
      "river bank    tensor([ 1.1295, -1.4725, -0.7296, -0.0901,  2.4970])\n"
     ]
    }
   ],
   "source": [
    "print('First 5 vector values for each instance of \"bank\".')\n",
    "print('')\n",
    "print(\"bank vault   \", str(token_vecs_sum[6][:5]))\n",
    "print(\"bank robber  \", str(token_vecs_sum[10][:5]))\n",
    "print(\"river bank   \", str(token_vecs_sum[19][:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector similarity for  *similar*  meanings:  0.95\n",
      "Vector similarity for *different* meanings:  0.68\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Calculate the cosine similarity between the word bank \n",
    "# in \"bank robber\" vs \"river bank\" (different meanings).\n",
    "diff_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[19])\n",
    "\n",
    "# Calculate the cosine similarity between the word bank\n",
    "# in \"bank robber\" vs \"bank vault\" (same meaning).\n",
    "same_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[6])\n",
    "\n",
    "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
    "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertModel, BertTokenizer\n",
    "class BertEmbedding:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = BertModel.from_pretrained('bert-base-uncased').eval()\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    def preprocess(self, text):\n",
    "        marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "        tokenized_text = self.tokenizer.tokenize(marked_text)\n",
    "        indexed_tokens = self.tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "        segments_ids = [1] * len(tokenized_text)\n",
    "        tokens_tensor = torch.tensor([indexed_tokens])\n",
    "        segments_tensors = torch.tensor([segments_ids])\n",
    "        return tokens_tensor, segments_tensors\n",
    "    \n",
    "    def embed(self, token_embeddings):\n",
    "        token_vecs_sum = []\n",
    "        for token in token_embeddings:\n",
    "            sum_vec = torch.sum(token[-4:], dim=0)\n",
    "            token_vecs_sum.append(sum_vec)\n",
    "        return token_vecs_sum\n",
    "    \n",
    "    def transform(self, text):\n",
    "        tokens_tensor, segments_tensors = self.preprocess(text)\n",
    "        with torch.no_grad():\n",
    "            encoded_layers, _ = self.model(tokens_tensor, segments_tensors)\n",
    "        token_embeddings = torch.stack(encoded_layers, dim=0)\n",
    "        token_embeddings = torch.squeeze(token_embeddings, dim=1)\n",
    "        token_embeddings = token_embeddings.permute(1,0,2)\n",
    "        embedding = self.embed(token_embeddings)\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize BertEmbeder\n",
    "EMBert = BertEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\"\n",
    "embbeding = EMBert.transform(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "diff_bank = 1 - cosine(embbeding[10], embbeding[19])\n",
    "same_bank = 1 - cosine(embbeding[10], embbeding[6])\n",
    "\n",
    "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
    "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypotesis testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "def measure_similarity(a, b):\n",
    "    diff_ = 1 - cosine(a, b)\n",
    "    print('Similarity for  *similar*  meanings: Cosine %.2f' % (diff_),end=\" \")\n",
    "    diff_ = np.linalg.norm(a-b)\n",
    "    print('Euclidian %.2f' % (diff_))\n",
    "    \n",
    "def embedding_index(sentence, word):\n",
    "    index = sentence.split(\" \").index(word)\n",
    "    return index+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context hypotehesis testing\n",
    "- BERT encodes words based on context meaning that the model looks at the whole sentence and encodes the word based on the meaining it has in the sentence. Words that are in a more similar context are more similar.\n",
    "- We also need to define what the core meaining of the word is. The core meaning of the word is the meaining that the word has regardless of the context. The only thing the word knows is its true meaning regarding to polysemi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "max_sentence = \"He brutally killed someone\"\n",
    "embedding = EMBert.transform(max_sentence)\n",
    "max_embedding = embedding[embedding_index(max_sentence,\"killed\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_sentence = \"He accidentaly killed someone\"\n",
    "embedding = EMBert.transform(min_sentence)\n",
    "min_embedding = embedding[embedding_index(min_sentence,\"killed\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "indif_sentence = \"He killed someone\"\n",
    "embedding = EMBert.transform(indif_sentence)\n",
    "indif_embedding = embedding[embedding_index(indif_sentence,\"killed\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "huge_sentence = \"Someone was killed in a horrifying manner\"\n",
    "embedding = EMBert.transform(huge_sentence)\n",
    "huge_embedding = embedding[embedding_index(huge_sentence, \"killed\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity for  *similar*  meanings: Cosine 0.78 Euclidian 42.97\n",
      "Similarity for  *similar*  meanings: Cosine 0.23 Euclidian 82.50\n",
      "Similarity for  *similar*  meanings: Cosine 0.78 Euclidian 43.36\n"
     ]
    }
   ],
   "source": [
    "measure_similarity(max_embedding, huge_embedding)\n",
    "measure_similarity(min_embedding, huge_embedding)\n",
    "measure_similarity(indif_embedding, huge_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_sentence = \"killed\"\n",
    "embedding = EMBert.transform(core_sentence)\n",
    "core_embedding = embedding[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity for  *similar*  meanings: Cosine 0.34 Euclidian 75.55\n",
      "Similarity for  *similar*  meanings: Cosine 0.21 Euclidian 84.49\n",
      "Similarity for  *similar*  meanings: Cosine 0.36 Euclidian 74.31\n"
     ]
    }
   ],
   "source": [
    "measure_similarity(max_embedding, core_embedding)\n",
    "measure_similarity(min_embedding, core_embedding)\n",
    "measure_similarity(indif_embedding, core_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <font size=\"3\"> What would be the best way to represent the core meaning of a word so that we can capture the differences between the core meaning and the meaning inside the context?</font>\n",
    "> - <font size=\"3\"> We can use an embedding which we create from averaging multiple vector embbedings from the same word inside multiple contexts</font>\n",
    "> - <font size=\"3\"> We can use the basic embbeding of the word without any context at all. This would be the most robust solution since bert probably outputs the most generic embeddings.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information retreival for vector embeddings\n",
    "- <font size=\"3\">We will use a large news corpus since our task data is also news related. The dataset can be found <a href=\"https://www.kaggle.com/snapcrack/all-the-news\"> here </a>. It was provided by Andrew Thompson and it contains 143,000 articles from 15 American publications. </font>\n",
    "- <font size=\"3\"> To be able to create our vector embeddings we have to extract sentences that contain our words from news articles. Because of that we need to also create an effective sentence extraction system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query:\n",
    "    def __init__(self, filename, threshold = 20):\n",
    "        self.news = open(filename, \"r\").read().replace(\"\\n\",\"\")\n",
    "        self.threshold = threshold\n",
    "        \n",
    "    def q(self, word):\n",
    "        sentences = [sentence.strip() + '.' for sentence in self.news.split(\".\") if ' '+word+' ' in sentence]\n",
    "        print(\"Before:\",len(sentences))\n",
    "        sentences = self.clean(sentences)\n",
    "        print(\"After:\",len(sentences))\n",
    "        return sentences\n",
    "    \n",
    "    def clean(self, sentences):\n",
    "        new = []\n",
    "        for i in sentences:\n",
    "            if len(i.split(\" \")) < self.threshold:\n",
    "                new.append(i)\n",
    "        return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can experiment with multiple tresholds. My assumption is that when the senteces are smaller that the word is closer to its core meaning because there isn't to much side context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 8372\n",
      "After: 2436\n"
     ]
    }
   ],
   "source": [
    "filename = \"datasets/News/articles1.txt\"\n",
    "query = Query(filename, 20)\n",
    "sentences = query.q(\"killed\")[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "text = \"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\"\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "padded_sequence = tokenizer.batch_encode_plus([text], return_tensors=\"pt\", max_length=40, pad_to_max_length=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel\n",
    "import torch\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "model = model.eval()\n",
    "with torch.no_grad():\n",
    "    out = model(padded_sequence['input_ids'], padded_sequence[\"attention_mask\"])\n",
    "print(len(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 40, 768])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states = out[2]\n",
    "token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "token_embeddings = token_embeddings[-4:,:]\n",
    "token_embeddings = torch.sum(token_embeddings, dim=0)\n",
    "token_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 768])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_vecs_sum = token_embeddings[0,:,:]\n",
    "token_vecs_sum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector similarity for  *similar*  meanings:  0.94\n",
      "Vector similarity for *different* meanings:  0.69\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "# Calculate the cosine similarity between the word bank \n",
    "# in \"bank robber\" vs \"river bank\" (different meanings).\n",
    "diff_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[19])\n",
    "\n",
    "# Calculate the cosine similarity between the word bank\n",
    "# in \"bank robber\" vs \"bank vault\" (same meaning).\n",
    "same_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[6])\n",
    "\n",
    "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
    "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert batch embedding\n",
    "Since we will feed mutliple sentences in batches we need a way to preprocess the sentences in batches instead of sentence by sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "class BertBatchEmbedding:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True).eval()\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "    \n",
    "    def transform(self, text):\n",
    "        padded_sequence = tokenizer.batch_encode_plus(text, return_tensors=\"pt\", max_length=40, pad_to_max_length=True)\n",
    "        with torch.no_grad():\n",
    "            out = self.model(padded_sequence['input_ids'], padded_sequence[\"attention_mask\"])\n",
    "        hidden_states = out[2]\n",
    "        token_embeddings = torch.stack(hidden_states, dim=0)\n",
    "        token_embeddings = self.embed(token_embeddings)\n",
    "        return token_embeddings\n",
    "    \n",
    "    def embed(self, token_embeddings):\n",
    "        token_embeddings = token_embeddings[-4:,:]\n",
    "        token_embeddings = torch.sum(token_embeddings, dim=0)\n",
    "        return token_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector similarity for  *similar*  meanings:  0.94\n",
      "Vector similarity for *different* meanings:  0.69\n"
     ]
    }
   ],
   "source": [
    "text = [\"After stealing money from the bank vault, the bank robber was seen fishing on the Mississippi river bank.\"]\n",
    "bertbatch = BertBatchEmbedding()\n",
    "embeddings = bertbatch.transform(text)\n",
    "token_vecs_sum = token_embeddings[0,:,:]\n",
    "\n",
    "diff_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[19])\n",
    "same_bank = 1 - cosine(token_vecs_sum[10], token_vecs_sum[6])\n",
    "\n",
    "print('Vector similarity for  *similar*  meanings:  %.2f' % same_bank)\n",
    "print('Vector similarity for *different* meanings:  %.2f' % diff_bank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are multiple ways to create vector embeddings from bert. You can avarage all the hidden layers. You can also avarage the last 4 layers. You can concat the last 4 layers instead of averaging. So this is also a part of our work that will need a lot of testing. We should probably create a table that contains all the different vector embeddings and compare their preformance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi vector embedding creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: 8372\n",
      "After: 2436\n"
     ]
    }
   ],
   "source": [
    "filename = \"datasets/News/articles1.txt\"\n",
    "query = Query(filename, 20)\n",
    "sentences = query.q(\"killed\")[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 40, 768])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bertbatch = BertBatchEmbedding()\n",
    "embeddings = bertbatch.transform(sentences)\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "tokenized_sentences = tokenizer.batch_encode_plus(sentences)[\"input_ids\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_embeddings = {}\n",
    "for i, tokenized_sentence in enumerate(tokenized_sentences):\n",
    "    for j, token in enumerate(tokenized_sentence):\n",
    "        if token not in core_embeddings:\n",
    "            core_embeddings[token] = embeddings[i,:][j,:]\n",
    "        else:\n",
    "            core_embeddings[token] = (core_embeddings[token]+embeddings[i,:][j,:])/2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.4054e+00, -1.0079e+00,  1.8521e-01,  9.0695e-01,  1.7104e-02,\n",
       "        -1.8542e+00, -4.2765e-01,  8.5572e-01, -2.1372e+00,  1.4927e+00,\n",
       "         6.3412e-01,  1.4819e+00, -1.3638e+00,  1.6461e+00, -2.7768e+00,\n",
       "        -2.6784e+00, -1.9579e-01, -3.5096e+00, -3.6820e+00,  5.4707e-01,\n",
       "         1.4618e+00, -7.2132e-01,  1.8020e+00,  1.6613e+00,  2.0224e+00,\n",
       "        -6.2111e-02,  1.6888e+00,  5.1060e-01, -1.5262e+00, -1.8507e+00,\n",
       "         8.6806e-01,  4.6912e-01,  8.8319e-01, -1.3538e+00, -8.9868e-01,\n",
       "        -1.6415e+00,  3.7351e-01, -1.3028e+00, -1.5394e+00,  1.1749e+00,\n",
       "        -2.0360e+00, -4.2730e+00, -1.3100e+00, -3.7897e-01,  2.2487e+00,\n",
       "        -9.2968e-01,  3.9641e+00,  3.1158e+00,  4.5993e+00, -8.1057e-01,\n",
       "        -2.6990e+00,  6.1405e-01,  1.7487e+00, -1.1270e+00,  1.8266e+00,\n",
       "         1.1985e+00, -1.0412e+00, -3.3504e+00, -8.8455e-01, -1.1766e+00,\n",
       "        -3.9828e-01,  1.1500e+00,  1.6837e+00, -2.6874e+00, -6.2709e-01,\n",
       "        -2.1924e-01, -2.6101e+00,  3.8683e+00, -1.7003e+00,  5.0080e-01,\n",
       "        -1.0417e+00, -3.1184e+00, -1.8285e-01,  4.7868e-01,  2.1699e+00,\n",
       "        -1.3849e+00,  1.1641e-01, -1.3884e+00, -5.1608e-01, -3.4742e+00,\n",
       "        -9.0032e-01, -1.1425e+00, -2.6651e+00, -7.8667e-02,  5.6590e-02,\n",
       "         1.7021e-03,  8.5508e-01, -5.5321e+00,  1.8548e+00,  2.4369e+00,\n",
       "         2.8759e-01, -1.5803e+00,  6.1590e-01,  1.6426e+00,  2.8081e-01,\n",
       "         2.2128e+00,  6.5963e-01,  1.1475e+00, -2.1161e-01, -1.7711e+00,\n",
       "         4.6780e-01,  1.6803e+00, -2.3191e+00,  1.1500e+00,  3.3596e-01,\n",
       "        -4.3345e-01, -8.3701e-01, -8.6968e-01,  2.9272e+00, -8.8360e-01,\n",
       "        -7.5841e-01, -1.2234e+00,  5.9418e-01,  1.1340e+00, -2.3247e+00,\n",
       "         3.2262e+00,  3.0158e+00,  4.2310e-01,  1.3051e+00, -3.6849e+00,\n",
       "        -1.9965e+00,  1.2228e-01, -1.6796e+00,  1.8566e+00,  1.0383e+00,\n",
       "        -2.0365e+00, -2.2221e-01, -3.6730e+00, -1.9325e+00,  3.8697e-01,\n",
       "        -5.5261e-01,  1.3186e+00,  5.7584e-02, -2.1852e+00,  1.9144e+00,\n",
       "        -2.8448e+00,  1.2179e-01, -1.3778e+00, -1.8482e+00, -9.9424e-02,\n",
       "         5.7221e-02,  2.3747e+00,  3.3389e+00,  2.6376e+00,  3.4632e+00,\n",
       "         5.4319e-01, -1.2130e+00, -3.4777e+00,  3.1281e+00,  1.3064e+00,\n",
       "        -4.3548e-02,  6.2668e-01, -1.4984e+00, -1.8525e+00, -1.8380e+00,\n",
       "         3.4058e+00,  1.0934e+00, -1.2394e+00, -1.5628e+00,  4.1774e-01,\n",
       "         1.6106e+00, -8.2576e-01, -1.3079e+00, -1.1995e+00,  4.6231e-01,\n",
       "         2.6602e+00, -3.8810e+00,  1.5452e+00, -9.4006e-01,  3.2562e+00,\n",
       "        -1.0397e+00,  8.3351e-01, -8.6130e-01,  8.3244e-01, -5.0282e-01,\n",
       "        -1.0391e+00, -3.6807e+00, -1.1280e+00, -1.5879e+00,  3.3074e-01,\n",
       "        -1.5002e-01, -2.4605e+00, -4.4130e+00,  3.0186e+00, -1.4629e+00,\n",
       "         1.1296e+00,  6.4440e-01, -5.9311e-01,  1.4388e+00,  1.4726e+00,\n",
       "         3.4459e-01, -3.2692e+00,  2.1699e+00, -1.1762e+00,  1.9326e+00,\n",
       "        -2.7512e+00,  1.5736e+00, -8.6902e-02,  1.7114e+00, -4.6318e-01,\n",
       "        -3.1195e+00,  3.7229e-01, -1.8061e+00, -1.0521e+00, -8.5949e-01,\n",
       "         2.8178e+00,  6.2647e-01,  8.5950e-01, -3.8383e+00,  1.6941e+00,\n",
       "        -3.0284e-01, -3.2091e+00, -1.1494e+00,  3.6104e+00,  3.3577e+00,\n",
       "        -1.3845e-01, -1.1376e+00,  1.9924e+00,  2.2718e-01, -2.4712e+00,\n",
       "        -6.3951e-01, -8.3277e-02, -5.6304e-01, -8.6450e-01, -3.8512e-01,\n",
       "         3.3877e+00,  5.3071e-01, -6.3482e-02,  1.3292e+00,  2.7448e-01,\n",
       "         1.0509e+00, -8.1037e-01, -4.6703e-01,  2.4497e+00, -3.9185e+00,\n",
       "         3.7965e-01, -4.9870e-01, -5.6106e-01,  2.3271e+00, -2.8071e+00,\n",
       "        -1.7178e+00,  5.2265e-01,  2.7199e+00, -4.6697e-01,  1.5165e+00,\n",
       "         2.0857e+00,  6.5591e-02,  9.8457e-01,  1.2238e+00,  3.6660e-01,\n",
       "        -9.5198e-02, -7.0314e-01, -1.5295e+00, -1.1939e+00,  8.9031e-01,\n",
       "        -4.1303e-01, -5.3870e-01, -6.1729e-01, -3.7970e+00,  1.0667e+00,\n",
       "         1.9197e+00, -1.9407e+00,  1.8606e+00,  4.3411e+00, -1.4596e+00,\n",
       "        -1.4493e+00, -1.6741e+00,  1.0528e-02,  4.3335e+00, -3.8999e-02,\n",
       "        -9.2816e-01, -1.2680e+00,  1.0873e+00,  2.8494e+00,  3.1803e+00,\n",
       "        -2.7471e+00, -1.5518e+00,  1.9756e+00, -2.1164e-01, -1.5323e+00,\n",
       "        -1.0503e-01,  8.1850e-01,  1.9715e+00, -1.0493e+00, -2.5203e+00,\n",
       "         3.8903e-01,  7.1363e-01, -3.0205e+00, -3.7209e+00, -1.3805e+00,\n",
       "        -3.1714e+00, -1.9545e+00,  2.4102e+00, -2.3982e+00, -1.3374e+00,\n",
       "        -1.8574e+00, -3.6008e-01,  4.6103e-01,  2.1099e+00,  1.1828e-02,\n",
       "         5.1088e-01,  4.0906e+00, -2.0751e+00,  5.3171e-01, -8.9976e-01,\n",
       "         9.9990e-01, -4.3556e-01,  1.7642e+00, -2.8423e+01,  3.4577e+00,\n",
       "         1.2676e+00,  2.0919e+00, -4.2653e-01,  5.1249e-01, -1.6518e+00,\n",
       "        -4.2004e-01, -3.0801e+00, -1.9694e+00,  1.3670e+00, -1.9170e+00,\n",
       "         1.6596e-01, -3.1866e+00, -1.7617e-01, -1.2788e+00,  1.6731e+00,\n",
       "        -5.1610e+00,  1.4590e+00,  3.0296e+00,  6.0163e-01, -7.2596e-01,\n",
       "         7.4197e-01,  1.1001e+00,  2.3260e+00,  1.2080e-01,  5.8465e-01,\n",
       "         8.8780e-02, -1.6354e-01, -1.6669e+00, -1.5953e+00,  3.0568e-01,\n",
       "        -3.1329e+00,  2.9030e+00, -2.0540e+00,  1.4992e+00, -1.1359e+00,\n",
       "        -2.4606e-01, -4.6671e-01, -7.3417e-01, -1.9254e+00, -1.6209e+00,\n",
       "         6.8382e-01, -1.7155e+00,  1.3132e+00, -1.4907e+00, -3.0757e+00,\n",
       "         2.8713e+00,  5.2305e-01, -1.0928e+00,  2.7726e+00,  3.8210e+00,\n",
       "        -3.2195e-01,  1.4185e+00,  3.3572e+00,  1.5883e+00, -2.0076e+00,\n",
       "         3.1561e+00, -1.9994e+00, -3.4939e+00,  2.9614e+00, -2.9261e-01,\n",
       "         1.7926e+00,  1.1992e+00, -5.7776e+00,  2.0244e+00, -3.4582e-01,\n",
       "         3.8217e-01, -1.6404e+00,  2.0996e-01, -2.7093e+00, -3.1868e-01,\n",
       "         4.6706e-02, -1.0985e+01, -2.2111e+00, -2.0322e+00,  3.8636e+00,\n",
       "         2.4533e+00,  7.2826e-01, -4.0500e-01, -1.5980e+00, -2.3830e+00,\n",
       "         2.2297e+00, -2.7480e+00,  2.3356e+00,  6.3080e-01, -1.9860e+00,\n",
       "         4.8447e-01, -6.9700e-01, -7.2671e-01, -9.9078e-01, -4.3776e-01,\n",
       "         2.5354e+00, -6.8197e-02, -1.3650e+00, -2.8625e+00,  2.5118e+00,\n",
       "        -1.4992e+00,  3.0310e-01,  1.0696e+00,  1.6984e+00, -6.6151e-01,\n",
       "        -2.2132e+00, -3.2842e+00,  2.3778e+00,  3.2151e+00,  2.3052e+00,\n",
       "        -2.7754e-01, -1.1774e+00, -1.9068e+00,  6.7092e-01, -5.9653e-01,\n",
       "        -4.6948e-01, -2.1368e+00,  7.2026e-01, -1.8893e+00,  2.3555e+00,\n",
       "         2.4886e+00, -2.4751e-01,  5.9714e-01, -8.4690e-01,  1.1314e+00,\n",
       "        -1.8446e+00, -3.1067e+00,  3.1021e+00, -3.7058e-01, -1.1473e+00,\n",
       "        -1.2897e+00,  5.6923e-01,  1.0259e+00,  1.2715e+00, -1.4884e+00,\n",
       "        -1.8741e+00,  2.5275e+00,  1.7905e+00, -9.7860e-01,  5.5102e-01,\n",
       "        -3.5045e+00,  2.4887e-01,  2.1905e+00,  2.1450e-01,  1.7598e+00,\n",
       "         1.2527e+00,  6.7795e-01,  2.4971e+00,  4.3856e+00, -1.7030e-01,\n",
       "         2.8919e+00,  1.0045e+00,  2.3879e+00, -1.0806e+00, -2.4102e+00,\n",
       "         1.3328e+00,  2.3972e-01, -4.3069e-01,  2.0756e+00, -1.4565e+00,\n",
       "         1.5575e+00, -2.6226e+00, -2.1982e+00, -3.9200e-01,  4.4545e+00,\n",
       "         7.0526e-01,  2.5336e+00, -4.8146e+00,  4.2939e+00,  1.0104e+00,\n",
       "         4.4722e-02,  1.4147e+00,  1.8878e+00,  1.6652e+00, -1.9576e+00,\n",
       "         3.1036e-01,  5.2066e-02,  4.6089e-01, -1.7816e+00, -8.9115e-01,\n",
       "        -5.8822e-03,  7.4534e-01,  2.5945e+00, -2.9356e+00, -1.6038e+00,\n",
       "        -9.3489e-01, -3.6210e+00,  1.7714e+00,  1.8760e+00,  2.1983e+00,\n",
       "        -9.6583e-01,  9.6553e-02, -1.6485e+00, -2.2712e+00, -3.0310e-01,\n",
       "        -1.6663e+00, -1.8279e+00, -2.9816e+00, -2.4410e+00,  3.4996e-01,\n",
       "        -4.3211e+00, -1.2851e+00,  2.6919e+00,  6.3094e-01,  3.6467e+00,\n",
       "         3.8895e-01,  1.2055e+00, -1.5339e+00, -1.8406e+00, -1.1044e+00,\n",
       "         3.9380e+00, -1.9388e+00, -2.2348e+00, -3.0100e+00,  4.3492e-01,\n",
       "        -7.7183e-01, -4.0608e-01,  2.7031e+00,  2.8123e-01,  1.9758e+00,\n",
       "        -1.1428e+00, -1.7431e+00,  3.3917e+00, -1.7106e+00,  1.3295e+00,\n",
       "         5.6102e-01, -8.7901e-01, -2.3757e+00, -1.8037e+00,  5.5730e-01,\n",
       "         7.5327e-01,  2.4936e-01,  1.5353e+00, -8.2054e-01, -2.5054e+00,\n",
       "        -5.2162e-01,  4.7721e-01,  1.5367e+00,  1.8577e+00, -8.2099e-01,\n",
       "        -2.0577e+00, -7.5216e-01, -1.6651e+00, -8.6005e-01,  7.2279e-01,\n",
       "         2.4227e+00,  2.0663e+00,  1.3789e+00, -5.5730e-01,  2.7343e+00,\n",
       "         3.3609e+00,  9.6887e-01, -7.9999e-01, -1.1559e+00, -8.0878e-01,\n",
       "        -2.2204e+00, -2.3474e+00, -5.0417e+00, -5.1782e+00,  6.1046e-01,\n",
       "        -2.6116e+00,  1.7472e+00,  1.2716e+00,  2.1760e+00,  2.7610e-01,\n",
       "         2.8002e+00, -4.1487e-01, -2.1354e-02, -7.3761e-01, -1.2472e+00,\n",
       "         2.9377e+00, -4.8515e-01, -6.0070e-01,  1.2703e+00,  1.4471e+00,\n",
       "        -3.0098e-01, -4.3047e-01, -1.6820e-02,  2.6895e-01, -2.5732e+00,\n",
       "        -9.6304e-01,  1.3369e+00,  1.4503e+00, -2.6757e+00,  4.5869e-01,\n",
       "        -2.0343e+00, -2.0418e+00, -1.3900e+00, -1.4514e+00,  2.4097e+00,\n",
       "         1.3913e+00, -1.7432e+00, -1.3487e+00,  3.9623e+00,  3.3970e+00,\n",
       "         2.9514e+00,  2.6715e+00, -1.1410e+00,  3.2449e+00, -3.0125e-02,\n",
       "         1.0874e-01,  2.7105e+00,  2.0875e+00, -1.0457e+00,  2.3061e+00,\n",
       "         6.6162e-01,  6.5617e-02,  7.8568e-01, -4.5494e+00,  4.8978e-01,\n",
       "        -9.2684e-01,  1.3175e+00, -1.1555e+00, -2.7970e-01,  2.1937e+00,\n",
       "         1.7909e+00,  6.8156e-01, -6.2459e-01, -2.5752e+00,  1.3432e+00,\n",
       "        -1.9248e+00,  8.6884e-01,  8.5203e-01, -8.2361e-01, -1.2760e+00,\n",
       "         3.1125e+00,  8.2589e-01,  1.1357e+00,  1.5141e+00, -4.1828e-02,\n",
       "         2.2166e-01, -5.1657e-01,  4.3856e+00,  1.3705e+00, -1.5385e+00,\n",
       "        -2.5990e+00,  1.3654e+00, -1.5835e+00, -5.7669e-02,  3.3151e-02,\n",
       "         6.7457e-01,  2.0568e+00, -2.3228e-01,  1.2838e+00, -8.2688e-01,\n",
       "        -1.9536e+00,  8.4604e-01,  2.8607e+00, -2.6468e+00, -7.9857e-01,\n",
       "         1.1162e+00,  2.8599e+00, -6.1671e-01,  2.8733e-01, -1.4557e-01,\n",
       "        -5.3319e-02, -1.2262e+00,  3.6296e+00, -2.8514e-01, -2.7776e+00,\n",
       "         2.4865e+00,  1.5742e-01,  2.4854e+00,  1.4416e+00, -4.4055e-02,\n",
       "         3.0492e+00, -4.1018e+00,  2.1474e+00,  1.2170e+00, -2.9041e+00,\n",
       "        -3.1928e+00,  4.7419e-01, -6.8712e-01,  3.0536e+00, -2.0196e+00,\n",
       "        -2.5383e+00, -4.0101e+00, -5.4138e-01, -6.2206e-01,  2.5908e+00,\n",
       "         1.7891e-01, -1.1800e+00, -1.2670e-01, -2.0690e+00,  4.8784e-01,\n",
       "        -5.8400e-01, -1.8875e+00, -1.0250e-01,  6.5477e-01,  3.4174e-01,\n",
       "         5.4267e-01, -3.2366e-01, -1.9919e+00,  1.9973e+00, -2.6514e-01,\n",
       "        -8.3068e-01,  9.6410e-01,  7.6854e-01, -1.1079e+00,  8.0122e-01,\n",
       "         1.2779e+00, -3.2511e+00, -2.4729e+00, -2.1680e+00,  1.1495e+00,\n",
       "        -1.6847e+00,  1.5356e+00, -1.8254e+00,  1.3608e+00,  7.7459e-03,\n",
       "        -7.2133e-01, -1.2323e+00, -2.5329e+00,  6.7650e-01,  2.0635e+00,\n",
       "        -8.2324e-01,  1.6146e+00, -9.0029e-01, -1.3282e+00, -6.3184e-01,\n",
       "        -5.6791e+00,  2.5730e+00, -2.4790e+00,  2.3721e-01, -4.0544e-01,\n",
       "         4.0815e-01,  1.4324e+00, -4.0191e+00, -1.1320e+00,  3.3007e+00,\n",
       "         1.7476e+00, -4.4540e-02,  4.6567e+00,  3.6747e-01,  1.4841e+00,\n",
       "        -5.8240e-01, -3.7144e+00,  1.2126e+00, -4.0412e-02,  1.8737e+00,\n",
       "         2.2457e-01, -1.9761e+00,  3.7352e-01,  3.7304e+00,  4.7420e-01,\n",
       "        -2.4395e+00,  3.3235e-01,  2.9332e+00,  1.4888e-01, -3.1996e+00,\n",
       "         2.6150e-01,  1.1926e+00, -1.7574e+00, -1.0876e+00, -1.4632e+00,\n",
       "        -1.5686e+00,  1.0508e+00,  1.0742e+00,  1.1355e+00, -1.4355e+00,\n",
       "        -1.7736e+00, -1.3448e-01, -2.1424e+00])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "core_embeddings[2730]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity for  *similar*  meanings: Cosine 0.65 Euclidian 52.40\n",
      "Similarity for  *similar*  meanings: Cosine 0.14 Euclidian 84.00\n",
      "Similarity for  *similar*  meanings: Cosine 0.65 Euclidian 51.72\n"
     ]
    }
   ],
   "source": [
    "measure_similarity(max_embedding, core_embeddings[2730])\n",
    "measure_similarity(min_embedding, core_embeddings[2730])\n",
    "measure_similarity(indif_embedding, core_embeddings[2730])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity for  *similar*  meanings: Cosine 0.30 Euclidian 76.15\n"
     ]
    }
   ],
   "source": [
    "measure_similarity(core_embeddings[2730], core_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
